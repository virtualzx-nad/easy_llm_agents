{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "217b929d-5298-476f-a4f2-2b3ea2a3b844",
   "metadata": {},
   "source": [
    "Learning a new command\n",
    "=========================\n",
    "Here the agent reads one example from its own README file and do online research to implement a new command, then try and use it immediately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c0e06ad-2d1a-41e2-9d7a-46312d211b0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lm_agent.agent import Agent\n",
    "agent = Agent(model='gpt-3.5-turbo', work_dir='gpt-3.5', disable=('delegate'), essential_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84512672-b904-4c3d-a9fb-7d0fc37d7af4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### First show the example and ask it to code up the new command\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "524076fc-976f-4700-80ec-7b0d77c9047f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Permissive Overseer>think requested. \"Plan out steps\". GRANTED.\n",
      "<Command think> {'thoughts': [{}], 'notes': [\"Use `reader` to read the section 'How to implement a new command' from https://raw.githubusercontent.com/virtualzx-nad/easy_llm_agents/main/README.md\", 'Use `search` to find a free weather API that can provide weather forecast for a date in the near future', 'Read the API documentation to understand the parameters and returns structure', 'Design a command that takes a date as input and returns the weather forecast for that date', 'Make sure the command does not return too much information to blow up the token limit', 'Submit and execute the Python code to create or update the command, but get approval before using it']}\n",
      "<Permissive Overseer>search requested. \"Find a free weather API that can provide weather forecast for a date in the near future\". GRANTED.\n",
      "<Command search> {'query': 'free weather API for future forecast', 'size': 3, 'tbs': None, 'tbm': None}\n",
      "<Command search> {'num_results': 3, 'result_len': 1096, 'titles': ['Open-Meteo.com: Free Open-Source Weather API', 'Free Weather API - WeatherAPI.com', 'Top 6 Best Free Weather APIs (2023)']}\n",
      "<Permissive Overseer>reader requested. \"Read the documentation of WeatherAPI.com to understand the parameters and returns structure\". GRANTED.\n",
      "<Command reader> {'url': 'https://www.weatherapi.com/docs/', 'instruction': 'WeatherAPI.com provides free weather data and forecast API suitable for any cartographic services'}\n",
      "<Command reader> {'lines': 3592, 'tokens': 38637, 'n': 15}\n",
      "Return is too long. Will summarize\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Incoming prompt is larger than model token limit",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[38;5;124;43mRead the section \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHow to implement a new command\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m from \u001b[39;49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;43m`https://raw.githubusercontent.com/virtualzx-nad/easy_llm_agents/main/README.md` to get the code and instructions for implementing new commands verbatim,\u001b[39;49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;43mthen write a command to get weather forecast for a date in the near future.\u001b[39;49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;43mWhen you design your command make sure it does not return too much information to blow up the token limit.\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;43mIf you choose to use an API, make sure you read the doc to understand the parameters and returns structure, and think about what need to be passed and returned for you command.\u001b[39;49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;43mI cannot provide you with API keys due to privacy restrictions, but the code can directly retrieve the API keys from `self.metadata`. \u001b[39;49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;43mDo not use APIs that are not free, and tell me what API keys need to be passed into metadata if you need them.  \u001b[39;49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;43mThe command will be created or updated as soon as you submit and execute the python code, but make sure to notify me and get approval before you start using them.\u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ela/lib/python3.10/site-packages/lm_agent/agent.py:424\u001b[0m, in \u001b[0;36mAgent.instruct\u001b[0;34m(self, human_input, context, max_ai_cycles, max_qa_rejections)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    423\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<< Proceed to format the next command that is needed to fulfill user instruction or question in Python dict. Do not repeat the last command. >>\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 424\u001b[0m llm_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_file:\n\u001b[1;32m    426\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconversation\u001b[38;5;241m.\u001b[39msave_history(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwork_dir, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_file))\n",
      "File \u001b[0;32m~/miniconda3/envs/ela/lib/python3.10/site-packages/lm_agent/agent.py:164\u001b[0m, in \u001b[0;36mAgent.get_response\u001b[0;34m(self, prompt, context)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Obtain a response from the LM\"\"\"\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 164\u001b[0m     llm_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconversation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtalk\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_command_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfootnote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraise_if_truncated\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mas_role\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m AnswerTruncated:\n\u001b[1;32m    172\u001b[0m     llm_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconversation\u001b[38;5;241m.\u001b[39mtalk(\n\u001b[1;32m    173\u001b[0m         prompt,\n\u001b[1;32m    174\u001b[0m         header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_command_list(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    178\u001b[0m         as_role\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    179\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/ela/lib/python3.10/site-packages/lm_agent/conversation.py:113\u001b[0m, in \u001b[0;36mLMConversation.talk\u001b[0;34m(self, content, footnote, header, raise_if_truncated, lead, as_role)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_footnote \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(footnote) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msummarize()\n\u001b[0;32m--> 113\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_completion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprevious\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msystem_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlead\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlead\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_options\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m top_choice \u001b[38;5;241m=\u001b[39m resp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m top_choice[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinish_reason\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlength\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m raise_if_truncated:\n",
      "File \u001b[0;32m~/miniconda3/envs/ela/lib/python3.10/site-packages/lm_agent/models/openai.py:75\u001b[0m, in \u001b[0;36mOpenAIModel.get_completion\u001b[0;34m(self, messages, system_prompt, text_only, lead, callback, **model_options)\u001b[0m\n\u001b[1;32m     73\u001b[0m actual_max \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_tokens \u001b[38;5;241m-\u001b[39m tokens \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m actual_max \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIncoming prompt is larger than model token limit\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m actual_max \u001b[38;5;241m<\u001b[39m options[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m options[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m actual_max \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m300\u001b[39m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Incoming prompt is larger than model token limit"
     ]
    }
   ],
   "source": [
    "print(agent.instruct(\"\"\"Read the section 'How to implement a new command' from \n",
    "`https://raw.githubusercontent.com/virtualzx-nad/easy_llm_agents/main/README.md` to get the code and instructions for implementing new commands verbatim,\n",
    "then write a command to get weather forecast for a date in the near future.\n",
    "When you design your command make sure it does not return too much information to blow up the token limit.\n",
    "If you choose to use an API, make sure you read the doc to understand the parameters and returns structure, and think about what need to be passed and returned for you command.\n",
    "I cannot provide you with API keys due to privacy restrictions, but the code can directly retrieve the API keys from `self.metadata`. \n",
    "Do not use APIs that are not free, and tell me what API keys need to be passed into metadata if you need them.  \n",
    "The command will be created or updated as soon as you submit and execute the python code, but make sure to notify me and get approval before you start using them.\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5849b00b-8e9f-46c9-979b-717bf78ec668",
   "metadata": {},
   "source": [
    "### Add API keys per its request\n",
    "Add the requested API key to metadata, if the agent requested it.  \n",
    "There are a few different APIs in this area and the agent usually choose from OpenWeatherMap, WeatherAPI and Open-Meteo APIs. \n",
    "If it chose one that is free but needs an API key, it will tell you to supply it here and you need to navigate to the site and get an \n",
    "API key then store it into metadata objects below. \n",
    "Do not tell the agent what the key is as that is probably not safe behavior.\n",
    "If it chose one that doesn't need API key (say Open Mateo) you can comment this block out and just proceed to later ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36515694-ca21-4ae7-a14d-d05f01bd73b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent.metadata['openweathermap_api_key'] ="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902ed43a-f89c-4ac0-953e-428fcac65176",
   "metadata": {},
   "source": [
    "### Check if new command is there\n",
    "Check the command list to make sure the new command is online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fa5e5d-a11d-46ba-8aff-f23cbaf5b12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(agent.generate_command_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9982869-7cfc-4d89-baab-0a81891487b8",
   "metadata": {},
   "source": [
    "### Now ask it to run the new command\n",
    "Now it is in metadata we can tell it to continue.  Then ask the question and see it uses the command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526be014-afc6-4b78-92d8-081053a0888d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(agent.instruct(\"\"\"OK I have added the API key to the metadata.  \n",
    "Now you can invoke command `weather_forecast` to check if it works correctly. \n",
    "What's the weather in San Francisco the day after tomorrow?\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966cc435-929a-418c-9140-753d58f033c0",
   "metadata": {},
   "source": [
    "### Under the hood\n",
    "\n",
    "Now we print out the full conversation history to see what went on under the hood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ee64692-eb7d-4879-94bd-643ab6d71cc8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: Use commands to fulfill instruction: `Read the section 'How to implement a new command' from \n",
      "`https://raw.githubusercontent.com/virtualzx-nad/easy_llm_agents/main/README.md` to get the code and instructions for implementing new commands verbatim,\n",
      "then write a command to get weather forecast for a date in the near future.\n",
      "When you design your command make sure it does not return too much information to blow up the token limit.\n",
      "If you choose to use an API, make sure you read the doc to understand the parameters and returns structure, and think about what need to be passed and returned for you command.\n",
      "I cannot provide you with API keys due to privacy restrictions, but the code can directly retrieve the API keys from `self.metadata`. \n",
      "Do not use APIs that are not free, and tell me what API keys need to be passed into metadata if you need them.  \n",
      "The command will be created or updated as soon as you submit and execute the python code, but make sure to notify me and get approval before you start using them.`\n",
      "assistant: {\n",
      "  \"notes\": [\n",
      "    \"Use `reader` to read the section 'How to implement a new command' from https://raw.githubusercontent.com/virtualzx-nad/easy_llm_agents/main/README.md\",\n",
      "    \"Use `search` to find a free weather API that can provide weather forecast for a date in the near future\",\n",
      "    \"Read the API documentation to understand the parameters and returns structure\",\n",
      "    \"Design a command that takes a date as input and returns the weather forecast for that date\",\n",
      "    \"Make sure the command does not return too much information to blow up the token limit\",\n",
      "    \"Submit and execute the Python code to create or update the command, but get approval before using it\"\n",
      "  ],\n",
      "  \"command\": \"think\",\n",
      "  \"summary\": \"Plan out steps\"\n",
      "}\n",
      "system: << Proceed to format the next command that is needed to fulfill user instruction or question in Python dict. Do not repeat the last command. >>\n",
      "assistant: {\n",
      "  \"notes\": [],\n",
      "  \"command\": \"search\",\n",
      "  \"summary\": \"Find a free weather API that can provide weather forecast for a date in the near future\",\n",
      "  \"content\": {\n",
      "    \"query\": \"free weather API for future forecast\"\n",
      "  }\n",
      "}\n",
      "system: \n",
      "`search` returns: \n",
      "1. Open-Meteo.com: Free Open-Source Weather API [https://open-meteo.com/]\n",
      "\n",
      "2. Free Weather API - WeatherAPI.com [https://www.weatherapi.com/, https://www.weatherapi.com/weather/, https://www.weatherapi.com/pricing.aspx, https://www.weatherapi.com/api-explorer.aspx, https://www.weatherapi.com/docs/]\n",
      "WeatherAPI .com  free weather API  and  weather  data and Geolocation  API  (JSON and ... 14 day daily, hourly and 15 min interval  weather forecast ,  future weather  ...\n",
      "‎ Pricing  · ‎ Docs  · ‎ Weather  · ‎ API Explorer\n",
      "\n",
      "3. Top 6 Best Free Weather APIs (2023) [https://rapidapi.com/blog/access-global-weather-data-with-these-weather-apis/]\n",
      "Feb 17, 2023  —  Here are the top 6 best free weather APIs for 2023: 1.  WeatherAPI.com ; 2. Forecast; 3. Meteostat; 4. Weather Embed; 5. Weather by API – Ninjas ...\n",
      "  Rating: 4.9  · ‎ 252 votes\n",
      "\n",
      "<< Please inspect each result and determine if you should read the page for more details.   Even if they do not give your the answer, they may help you refine your search.  If a search returns no relevant results, try break it into many simpler searches. >>\n",
      "<< Consider these information returned by the system in response to the previous command, and describe the next command needed with a Python dict.  Do not repeat the last command. >>\n",
      "assistant: {\n",
      "  \"notes\": [\n",
      "    \"WeatherAPI.com seems to be a good option as it provides weather forecast for up to 14 days in advance\",\n",
      "    \"Use `reader` to read the documentation and understand the parameters and returns structure\"\n",
      "  ],\n",
      "  \"command\": \"reader\",\n",
      "  \"summary\": \"Read the documentation of WeatherAPI.com to understand the parameters and returns structure\",\n",
      "  \"content\": {\n",
      "    \"url\": \"https://www.weatherapi.com/docs/\",\n",
      "    \"extract\": \"WeatherAPI.com provides free weather data and forecast API suitable for any cartographic services\",\n",
      "    \"save_as\": \"weather_api_docs.txt\"\n",
      "  }\n",
      "}\n",
      "system: \n",
      "`reader` returns: WeatherAPI.com provides free weather data and forecast API suitable for any cartographic services. The API provides real-time weather, 14 day weather forecast, historical weather, marine weather and tide data, future weather (up to 300 days ahead), daily and hourly intervals, 15 min interval (Enterprise only), astronomy, time zone, sports, location data, search or autocomplete API, weather alerts, air quality data, and bulk request.\n",
      "\n",
      "To use the API, users need to sign up and find their API key under their account. API access to the data is protected by an API key. The API can be accessed by making HTTP or HTTPS request to the base URL: http://api.weatherapi.com/v1. The API provides various APIs such as current weather, forecast, search or autocomplete, history, marine, future, time zone, sports, astronomy, and IP lookup.\n",
      "\n",
      "For the forecast API method, the `days` parameter is required and should be a number between 1 and 14. If no `days` parameter is provided then only today's weather is returned.\n",
      "\n",
      "For the History and Future API methods, the `dt` parameter is required and should be in yyyy-MM-dd format. For the History API method, `dt` should be on or after 1st Jan, 2010. For the Forecast API method, `dt` should be between today and next 14 days. For the Future API method, `dt` should be between 14 days and 300 days from today in the future.\n",
      "\n",
      "The `unixdt` parameter is optional and has the same restrictions as the `dt` parameter. The `end_dt` parameter is available for the History API method and should be on or after 1st Jan, 2010. The `unixend_dt` parameter has the same restrictions as the `end_dt` parameter.\n",
      "\n",
      "The `hour`, `alerts`, `aqi`, `tides`, `tp`, and `lang` parameters are optional. The `lang` parameter should be passed with a language code from the table provided in the text.\n",
      "\n",
      "The Location Object is returned with each API response and provides information about the location including geo points, name, region, country and time zone information.\n",
      "\n",
      "The Forecast API method returns alerts and warnings issued by government agencies (USA, UK, Europe and Rest of the World) as an array if available for the location provided. To get alerts back in the response from Forecast API, pass the parameter `alerts=yes`.\n",
      "\n",
      "Air Quality data is returned in the Forecast API and Realtime API response. Depending upon your subscription plan we provide current and 3 day air quality data for the given location in json and xml. It provides air quality index (see below) data on major pollutant gases like Carbon monoxide (CO), Ozone (O3), Nitrogen dioxide (NO2), Sulphur dioxide (SO2), PM 2.5 and PM 10. By default air quality data is not returned. To get air quality data back in the response from Forecast API and Realtime API, pass the parameter aqi=yes.\n",
      "\n",
      "If you are on Pro+, Business or Enterprise plan then you may use our bulk weather option to send multiple locations to get weather for all the locations sent in a single request.\n",
      "\n",
      "Each location sent in bulk operation is counted as 1 call. It works for all the API methods except Search API.\n",
      "\n",
      "For bulk you need to pass in the querysting q=bulk and then pass a json body with utf-8 encoding. All the the other request parameters will be passed as query as usual.\n",
      "\n",
      "Json format for sending multiple locations in the body.\n",
      "\n",
      "{\n",
      "    \"locations\": [\n",
      "        {\n",
      "            \"q\": \"53,-0.12\",\n",
      "            \"custom_id\": \"my-id-1\"\n",
      "        },\n",
      "        {\n",
      "            \"q\": \"London\",\n",
      "            \"custom_id\": \"any-internal-id\"\n",
      "        },\n",
      "        {\n",
      "            \"q\": \"90201\",\n",
      "            \"custom_id\": \"us-zipcode-id-765\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\n",
      "Json format explanation\n",
      "\n",
      "Parameter\n",
      "\n",
      "Description\n",
      "\n",
      "q (required)\n",
      "\n",
      "You may pass lat and lon, US zipcode, UK postcode, city name, IP, etc.\n",
      "\n",
      "custom_id (optional)\n",
      "\n",
      "We will return this custom_id back in the response for you to use it at your end. It is for better management at your end. We don't use this id for anything.\n",
      "\n",
      "Bulk Request Example\n",
      "\n",
      "curl --location --request GET 'http://api.weatherapi.com/v1/current.json?key=YOUR_API_KEY&q=bulk' \\\n",
      "--header 'Content-Type: application/json' \\\n",
      "--data-raw '{\n",
      "    \"locations\": [\n",
      "        {\n",
      "            \"q\": \"53,-0.12\",\n",
      "\n",
      "Feels like temperature as fahrenheit\n",
      "\n",
      "windchill_c\n",
      "\n",
      "decimal\n",
      "\n",
      "Windchill temperature in celcius\n",
      "\n",
      "windchill_f\n",
      "\n",
      "decimal\n",
      "\n",
      "Windchill temperature in fahrenheit\n",
      "\n",
      "heatindex_c\n",
      "\n",
      "decimal\n",
      "\n",
      "Heat index in celcius\n",
      "\n",
      "heatindex_f\n",
      "\n",
      "decimal\n",
      "\n",
      "Heat index in fahrenheit\n",
      "\n",
      "dewpoint_c\n",
      "\n",
      "decimal\n",
      "\n",
      "Dew point in celcius\n",
      "\n",
      "dewpoint_f\n",
      "\n",
      "decimal\n",
      "\n",
      "Dew point in fahrenheit\n",
      "\n",
      "will_it_rain\n",
      "\n",
      "int\n",
      "\n",
      "1 = Yes 0 = No\n",
      "\n",
      "                                        Will it will rain or not\n",
      "\n",
      "will_it_snow\n",
      "\n",
      "int\n",
      "\n",
      "1 = Yes 0 = No\n",
      "\n",
      "                                        Will it snow or not\n",
      "\n",
      "is_day\n",
      "\n",
      "int\n",
      "\n",
      "1 = Yes 0 = No\n",
      "\n",
      "                                        Whether to show day condition icon or night icon\n",
      "\n",
      "vis_km\n",
      "\n",
      "decimal\n",
      "\n",
      "Visibility in kilometer\n",
      "\n",
      "vis_miles\n",
      "\n",
      "decimal\n",
      "\n",
      "Visibility in miles\n",
      "\n",
      "Marine Weather API\n",
      "\n",
      "                            Marine weather API method returns upto next 7 day (depending upon your price plan level) marine and sailing weather forecast and tide data (depending upon your price plan level) as json or xml. The data is returned as a Marine Object.\n",
      "\n",
      "                            Marine object\n",
      "\n",
      "\n",
      "<< Consider these information returned by the system in response to the previous command, and describe the next command needed with a Python dict.  Do not repeat the last command. >>\n"
     ]
    }
   ],
   "source": [
    "for entry in agent.conversation.raw_history:\n",
    "    print(f\"{entry['role']}: {entry['content']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79078df6-7aa6-41f2-9294-7b449d0d2cc6",
   "metadata": {},
   "source": [
    "### Check how much this has cost. \n",
    "\n",
    "Not cheap for a weather forecast, but decent for coding a new functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bc3c7f-3e5c-4b1e-93d7-fb4e66fbe623",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Total OpenAI cost: ${agent.model.total_cost():.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
